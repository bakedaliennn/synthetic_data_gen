{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b8655c",
   "metadata": {},
   "source": [
    "# Synthetic Marketing Data Generation\n",
    "**Project:** Marketing BI Dashboard  \n",
    "**Role:** Data Engineering & ETL Simulation  \n",
    "**Output:** Star Schema (Fact + Dimensions)\n",
    "\n",
    "This notebook generates a realistic dataset for marketing analytics. It simulates performance across Programmatic, Search, and Social channels, applying specific seasonality rules and \"insight spikes\" to test dashboard capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2ee583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded. Ready to generate schema.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# CONFIGURATION\n",
    "# Set the output directory here. Use '.' for current directory.\n",
    "OUTPUT_DIR = '../docs' \n",
    "\n",
    "print(\"Libraries loaded. Ready to generate schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff8944",
   "metadata": {},
   "source": [
    "## 1. Generate Dimensions (Metadata)\n",
    "We establish the \"Nouns\" of our analysis: **Time, Source, and Campaign**. \n",
    "* **Dim_Date:** A continuous 15-month range.\n",
    "* **Dim_Source:** 8 unique platforms mapped to 3 major channels.\n",
    "* **Dim_Campaign:** 8 campaigns with specific objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79db6a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dimensions...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating Dimensions...\")\n",
    "\n",
    "# --- DIM_DATE (15 Months: Jan 2023 - Mar 2024) ---\n",
    "start_date = datetime(2023, 1, 1)\n",
    "dates = [start_date + timedelta(days=x) for x in range(456)] \n",
    "dim_date = pd.DataFrame({'date': dates})\n",
    "\n",
    "# Creating an Integer Date Key (YYYYMMDD) is standard practice for Fact tables\n",
    "dim_date['date_key'] = dim_date['date'].dt.strftime('%Y%m%d').astype(int)\n",
    "dim_date['year'] = dim_date['date'].dt.year\n",
    "dim_date['month'] = dim_date['date'].dt.month\n",
    "dim_date['month_name'] = dim_date['date'].dt.strftime('%b')\n",
    "dim_date['quarter'] = dim_date['date'].dt.quarter\n",
    "dim_date['is_weekend'] = dim_date['date'].dt.dayofweek >= 5\n",
    "\n",
    "# --- DIM_SOURCE (8 Sources, Mapped to Channels) ---\n",
    "sources_data = [\n",
    "    (1, 'Amazon Ad Server', 'Programmatic'), \n",
    "    (2, 'StackAdapt', 'Programmatic'), \n",
    "    (3, 'DV360', 'Programmatic'), \n",
    "    (4, 'Search Ads 360', 'Paid Search'), \n",
    "    (5, 'Bing Ads', 'Paid Search'), \n",
    "    (6, 'Facebook', 'Paid Social'), \n",
    "    (7, 'LinkedIn Ads', 'Paid Social'), \n",
    "    (8, 'Organic Search', 'Organic')\n",
    "]\n",
    "dim_source = pd.DataFrame(sources_data, columns=['source_id', 'source_name', 'channel'])\n",
    "\n",
    "# --- DIM_CAMPAIGN (Mapped to Channel & Objective) ---\n",
    "campaign_config = [\n",
    "    (\"Business-focused zero tolerance\", \"Programmatic\", \"Brand Awareness\"), \n",
    "    (\"Profound intangible policy\", \"Programmatic\", \"Brand Awareness\"),\n",
    "    (\"Networked value-added time-frame\", \"Programmatic\", \"Consideration\"), \n",
    "    (\"Persistent 24/7 attitude\", \"Paid Social\", \"Lead Gen\"), \n",
    "    (\"Centralized modular throughput\", \"Paid Social\", \"Conversion\"), \n",
    "    (\"Integrated dedicated contingency\", \"Paid Search\", \"Conversion\"), \n",
    "    (\"Automated uniform software\", \"Paid Search\", \"Lead Gen\"), \n",
    "    (\"Cross-platform static hierarchy\", \"Organic\", \"Traffic\")\n",
    "]\n",
    "\n",
    "campaign_rows = []\n",
    "id_counter = 1\n",
    "\n",
    "for name, scope, objective in campaign_config:\n",
    "    # Create 2 Ad Sets per Campaign to enable hierarchy testing\n",
    "    for tier in ['_Tier1', '_Tier2']:\n",
    "        campaign_rows.append({\n",
    "            'campaign_id': id_counter,\n",
    "            'campaign_name': name, \n",
    "            'ad_set_name': f\"{name}{tier}\", \n",
    "            'channel_scope': scope, \n",
    "            'objective': objective\n",
    "        })\n",
    "        id_counter += 1\n",
    "dim_campaign = pd.DataFrame(campaign_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99fe50f",
   "metadata": {},
   "source": [
    "## 2. Generate Fact Table\n",
    "We create the skeleton of our data by cross-joining Campaigns, Sources, and Dates. This results in ~20k rows of daily data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c326d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact Table Skeleton Created: 16416 rows.\n"
     ]
    }
   ],
   "source": [
    "# Step A: Link Campaigns to Sources (Logical Join)\n",
    "# This prevents \"Search\" campaigns from erroneously appearing on \"Facebook\"\n",
    "schema_link = dim_campaign.merge(dim_source, left_on='channel_scope', right_on='channel')\n",
    "\n",
    "# Step B: Create the Skeleton (Cross Join with Date)\n",
    "df_fact = schema_link.merge(dim_date[['date_key', 'is_weekend', 'year', 'month']], how='cross')\n",
    "\n",
    "N = len(df_fact)\n",
    "print(f\"Fact Table Skeleton Created: {N} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c9c01",
   "metadata": {},
   "source": [
    "## 3. Apply Vectorized Metric Logic\n",
    "Here we inject \"realism\" into the data. Instead of random noise, we use:\n",
    "1.  **Seasonality:** Weekend dips in traffic.\n",
    "2.  **Channel Distributions:** \"Search\" has high CPC/CTR, while \"Programmatic\" has high volume/low CTR.\n",
    "3.  **Storytelling:** We inject specific \"spikes\" (e.g., an August traffic boom) to ensure the dashboard has insights to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b6c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric Logic Applied.\n"
     ]
    }
   ],
   "source": [
    "# 1. Seasonality Mask (Lower on weekends)\n",
    "seasonality = np.where(df_fact['is_weekend'], 0.7, 1.1)\n",
    "\n",
    "# 2. Initialize Arrays\n",
    "base_imps = np.zeros(N)\n",
    "ctrs = np.zeros(N)\n",
    "cpcs = np.zeros(N)\n",
    "\n",
    "# 3. Apply Channel-Specific Distributions\n",
    "# Programmatic (High Volume, Low CTR/CPC)\n",
    "mask_prog = df_fact['channel'] == 'Programmatic'\n",
    "s_prog = mask_prog.sum()\n",
    "base_imps[mask_prog] = np.random.randint(5000, 15000, s_prog)\n",
    "ctrs[mask_prog] = np.random.uniform(0.003, 0.007, s_prog) \n",
    "cpcs[mask_prog] = np.random.uniform(0.30, 0.90, s_prog)\n",
    "\n",
    "# Search (Low Volume, High CTR/CPC)\n",
    "mask_search = df_fact['channel'] == 'Paid Search'\n",
    "s_search = mask_search.sum()\n",
    "base_imps[mask_search] = np.random.randint(300, 1200, s_search)\n",
    "ctrs[mask_search] = np.random.uniform(0.08, 0.12, s_search) \n",
    "cpcs[mask_search] = np.random.uniform(2.50, 6.00, s_search)\n",
    "\n",
    "# Social (Mid Volume, Mid CTR/CPC)\n",
    "mask_social = df_fact['channel'] == 'Paid Social'\n",
    "s_social = mask_social.sum()\n",
    "base_imps[mask_social] = np.random.randint(1000, 4000, s_social)\n",
    "ctrs[mask_social] = np.random.uniform(0.015, 0.035, s_social) \n",
    "cpcs[mask_social] = np.random.uniform(1.50, 3.50, s_social)\n",
    "\n",
    "# Organic (No Cost)\n",
    "mask_org = df_fact['channel'] == 'Organic'\n",
    "s_org = mask_org.sum()\n",
    "base_imps[mask_org] = np.random.randint(1000, 3000, s_org)\n",
    "ctrs[mask_org] = np.random.uniform(0.05, 0.08, s_org)\n",
    "cpcs[mask_org] = 0.0\n",
    "\n",
    "# 4. Inject Strategic Insights (The \"Story\" Layer)\n",
    "final_imps = base_imps * seasonality\n",
    "\n",
    "# INSIGHT 1: \"The August Spike\" - Programmatic impressions triple in Aug 2023\n",
    "mask_spike = (df_fact['year'] == 2023) & (df_fact['month'] == 8) & (df_fact['channel'] == 'Programmatic')\n",
    "final_imps[mask_spike] *= 3.0\n",
    "\n",
    "# INSIGHT 2: \"December Efficiency\" - Search CPC drops by 30% in Dec 2023\n",
    "mask_effic = (df_fact['year'] == 2023) & (df_fact['month'] == 12) & (df_fact['channel'] == 'Paid Search')\n",
    "cpcs[mask_effic] *= 0.7\n",
    "\n",
    "# 5. Final Calculations\n",
    "df_fact['impressions'] = final_imps.astype(int)\n",
    "df_fact['clicks'] = (df_fact['impressions'] * ctrs).astype(int)\n",
    "df_fact['spend'] = (df_fact['clicks'] * cpcs).round(2)\n",
    "\n",
    "# Conversion Rate (Randomized)\n",
    "conv_rates = np.random.uniform(0.05, 0.15, N)\n",
    "df_fact['conversions'] = (df_fact['clicks'] * conv_rates).astype(int)\n",
    "\n",
    "# Video Views (Only relevant for Display/Social)\n",
    "df_fact['video_views'] = 0\n",
    "mask_video = df_fact['channel'].isin(['Programmatic', 'Paid Social'])\n",
    "df_fact.loc[mask_video, 'video_views'] = (\n",
    "    df_fact.loc[mask_video, 'impressions'] * 0.40 * np.random.uniform(0.8, 1.2, mask_video.sum())\n",
    ").astype(int)\n",
    "\n",
    "print(\"Metric Logic Applied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cd5be",
   "metadata": {},
   "source": [
    "## 4. Export Data\n",
    "We select the relevant columns for our Fact table and export the Star Schema files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14045587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: 4 Star Schema files generated!\n",
      "Files ready in: d:\\VSCode\\synthetic_data_gen\\docs\n"
     ]
    }
   ],
   "source": [
    "# Select only keys and metrics for the Fact Table\n",
    "fact_columns = ['date_key', 'source_id', 'campaign_id', 'impressions', 'clicks', 'spend', 'conversions', 'video_views']\n",
    "fact_final = df_fact[fact_columns]\n",
    "\n",
    "# Clean up dimensions (remove helper columns)\n",
    "dim_campaign_final = dim_campaign.drop(columns=['channel_scope'])\n",
    "\n",
    "# Export\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "dim_date.to_csv(os.path.join(OUTPUT_DIR, 'dim_date.csv'), index=False)\n",
    "dim_source.to_csv(os.path.join(OUTPUT_DIR, 'dim_source.csv'), index=False)\n",
    "dim_campaign_final.to_csv(os.path.join(OUTPUT_DIR, 'dim_campaign.csv'), index=False)\n",
    "fact_final.to_csv(os.path.join(OUTPUT_DIR, 'fact_performance.csv'), index=False)\n",
    "\n",
    "print(\"SUCCESS: 4 Star Schema files generated!\")\n",
    "print(f\"Files ready in: {os.path.abspath(OUTPUT_DIR)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic_data_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
